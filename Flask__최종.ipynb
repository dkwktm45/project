{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9486d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from opencv-python) (1.21.6)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24f1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask-cors in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: Six in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flask-cors) (1.16.0)\n",
      "Requirement already satisfied: Flask>=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flask-cors) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Flask>=0.9->flask-cors) (8.1.3)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Flask>=0.9->flask-cors) (3.1.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Flask>=0.9->flask-cors) (4.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from click>=8.0->Flask>=0.9->flask-cors) (0.4.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask>=0.9->flask-cors) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask>=0.9->flask-cors) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Jinja2>=3.0->Flask>=0.9->flask-cors) (2.1.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ceab2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (0.8.10)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (1.21.6)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from mediapipe) (3.20.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from mediapipe) (3.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->mediapipe) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->mediapipe) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->mediapipe) (9.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.2.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dc3f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simplejson in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.17.6)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e72fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 거리 구하는 함수\n",
    "def euclidean_distance(pt1, pt2):\n",
    "    distance = 0\n",
    "    for i in range(len(pt1)):\n",
    "        distance += (pt1[i] - pt2[i]) ** 2\n",
    "    return distance ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb93db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "pi = math.pi\n",
    "# 구면 좌표로 변환하는 함수\n",
    "def spherical(x, y, z):\n",
    "    r= np.sqrt(x**2+y**2+z**2)\n",
    "    theta = math.acos(y/r)/pi*180\n",
    "    if x == 0 :\n",
    "        phi = 0\n",
    "    else :\n",
    "        phi = math.atan2(x,z)/pi*180   \n",
    "    return r, theta, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623015ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833b3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f31ad2",
   "metadata": {},
   "source": [
    "--------- 체스트 플라이 정면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc9ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def chestflyFront(data):\n",
    "    annotated_image=None\n",
    "    dis = 0\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "    feedback_l = None\n",
    "    feedback_r = None\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks_3d = results.pose_world_landmarks.landmark  \n",
    "                l_t_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_THUMB.value].x*100\n",
    "                l_t_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_THUMB.value].y*100\n",
    "                l_t_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_THUMB.value].z*100           \n",
    "                left_thumb = [l_t_x, l_t_y, l_t_z]\n",
    "                r_t_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_THUMB.value].x*100\n",
    "                r_t_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_THUMB.value].y*100\n",
    "                r_t_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_THUMB.value].z*100\n",
    "                right_thumb = [r_t_x, r_t_y, r_t_z]\n",
    "                dis = euclidean_distance(left_thumb, right_thumb)\n",
    "\n",
    "\n",
    "                ##### 팔의 위치\n",
    "                if l_t_z>-13 or r_t_z>-13 :\n",
    "                    feedback = None\n",
    "                    if -44.5<=l_t_y and -44.5<=r_t_y :\n",
    "                        feedback = \"GREAT!!\"\n",
    "                        #cv2.rectangle(image, (300, 400), (700, 500), (211, 211, 211), -1)    \n",
    "                        cv2.putText(image, feedback, (int(0.4*w), int(0.98*h)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "                    if l_t_y < -44.5 :\n",
    "                        feedback_l = \"Down left\" ###### 화면 반전으로 왼쪽, 오른쪽 바뀜\n",
    "                        feedback = None\n",
    "                    else :\n",
    "                        feedback_l = None         \n",
    "                    if r_t_y < -44.5 :\n",
    "                        feedback_r = \"Down right\"\n",
    "                        feedback = None\n",
    "                    else :\n",
    "                        feedback_r = None\n",
    "                if dis > 110 :\n",
    "                    state = \"PUSH\"\n",
    "##                if dis < 25 and state == 'PUSH':\n",
    "                if dis < 25:\n",
    "                    state = \"PULL\"\n",
    "                    cnt = 1\n",
    "                    print(\"운동 횟수 : \", cnt)\n",
    "                    if feedback=='GREAT!!':\n",
    "                        g_cnt= 1\n",
    "                        print(\"정자세 횟수 : \", cnt)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback, feedback_l, feedback_r, dis\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaecda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76bdef94",
   "metadata": {},
   "source": [
    "--------- 시티드 로우 측면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6cb9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def seatedrowSide(data):\n",
    "    annotated_image=None\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks = results.pose_world_landmarks.landmark\n",
    "                ##### 추출하고자 하는 좌표 추출\n",
    "                ####################  왼쪽 어깨\n",
    "                r_shou = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y,\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z ]\n",
    "                r_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].z]\n",
    "                r_eye = [landmarks[mp_pose.PoseLandmark.RIGHT_EYE.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EYE.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EYE.value].z]\n",
    "                r_ear = [landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].z]\n",
    "                r_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z]\n",
    "                r_shou_x = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x*100\n",
    "                r_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z]\n",
    "                dis = euclidean_distance(r_shou, r_wrist)*100\n",
    "                print(dis)\n",
    "\n",
    "                angle = calculateAngle(r_eye, r_shou, r_hip)\n",
    "                print(angle)\n",
    "                angle_c = calculateAngle(r_shou, r_hip, r_knee)\n",
    "\n",
    "                ##### 팔의 각도 체크 & 횟수 카운트\n",
    "                if dis > 45 :\n",
    "                    state = \"down\"\n",
    "                    stage = \"down\"\n",
    "                    feedback = \"\"\n",
    "                if dis < 34 and state == 'down':\n",
    "                    state = \"up\"\n",
    "                    cnt=1\n",
    "                    print(counter)\n",
    "\n",
    "\n",
    "                if angle < 105 :\n",
    "                    feedback = \"keep your head up\"\n",
    "                if angle > 170 :\n",
    "                    feedback = \"keep your head down\"\n",
    "                if 100 < angle_c < 120 and stage == 'down' :\n",
    "                    stage = 'up'\n",
    "                    feedback = \"great\"\n",
    "                if angle_c > 130 :\n",
    "                    feedback = \"fix your posture\"\n",
    "                    if feedback=='great':\n",
    "                        g_cnt=1\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ecb6d",
   "metadata": {},
   "source": [
    "--------- 시티드 로우 후면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14408a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def seatedrowBack(data):\n",
    "    annotated_image=None\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "    feedback_l = None\n",
    "    feedback_r = None\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks_3d = results.pose_world_landmarks.landmark  \n",
    "                ##### 추출하고자 하는 좌표 추출\n",
    "                ####################  왼쪽 어깨\n",
    "                sh_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x*100\n",
    "                sh_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y*100\n",
    "                sh_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z*100\n",
    "                ####################  왼쪽 팔꿈치\n",
    "                el_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].x*100\n",
    "                el_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].y*100\n",
    "                el_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].z*100\n",
    "                ####################  오른쪽 어깨\n",
    "                sh_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x*100\n",
    "                sh_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y*100\n",
    "                sh_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z*100\n",
    "                ####################  오른쪽 팔꿈치\n",
    "                el_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x*100\n",
    "                el_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y*100\n",
    "                el_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].z*100            \n",
    "                ##### 어깨를 중심으로 만들기\n",
    "                ################ 내가 원하는 좌표(팔꿈치) - 기준이 되고 싶은 좌표(어깨)\n",
    "                el_l_x, el_l_y, el_l_z = el_l_x-sh_l_x, el_l_y-sh_l_y, el_l_z-sh_l_z\n",
    "                el_r_x, el_r_y, el_r_z = el_r_x-sh_r_x, el_r_y-sh_r_y, el_r_z-sh_r_z\n",
    "                ##### 구면좌표로 변환\n",
    "                l_r, l_theta, l_phi = spherical(el_l_x, el_l_y, el_l_z)\n",
    "                r_r, r_theta, r_phi = spherical(el_r_x, el_r_y, el_r_z)\n",
    "\n",
    "\n",
    "                ##### 팔의 각도 체크 & 횟수 카운트\n",
    "                if l_theta > 50 :\n",
    "                    feedback_l = \"Put your left elbows down\"\n",
    "                else :\n",
    "                    feedback_l = \"\"\n",
    "\n",
    "\n",
    "                if r_theta > 50 :\n",
    "                    feedback_r = \"Put your right elbows down\"\n",
    "                else :\n",
    "                    feedback_r = \"\"\n",
    "\n",
    "\n",
    "                if l_phi > 8 :\n",
    "                    state = \"down\"\n",
    "                    feedback=\"\"\n",
    "                if l_phi < -42 and stage == \"down\":\n",
    "                    state = \"up\"\n",
    "                    counter = 1\n",
    "                    feedback=\"\"\n",
    "                    if l_theta <= 49  and r_theta <= 49 :\n",
    "                        feedback=\"great\"\n",
    "                        if feedback==\"great\":\n",
    "                            g_cnt=1\n",
    "                    \n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback, feedback_l, feedback_r\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478abb9",
   "metadata": {},
   "source": [
    "--------- 덤벨 숄더 프레스 정면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541e6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def dumbbellFront(data):\n",
    "    annotated_image=None\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "    feedback_l = None\n",
    "    feedback_r = None\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks_3d = results.pose_world_landmarks.landmark  \n",
    "                ##### 추출하고자 하는 좌표 추출\n",
    "                ####################  왼쪽 어깨\n",
    "                sh_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x*100\n",
    "                sh_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y*100\n",
    "                sh_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z*100\n",
    "                ####################  왼쪽 팔꿈치\n",
    "                el_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].x*100\n",
    "                el_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].y*100\n",
    "                el_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].z*100\n",
    "                ####################  오른쪽 어깨\n",
    "                sh_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x*100\n",
    "                sh_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y*100\n",
    "                sh_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z*100\n",
    "                ####################  오른쪽 팔꿈치\n",
    "                el_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x*100\n",
    "                el_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y*100\n",
    "                el_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].z*100            \n",
    "                ##### 어깨를 중심으로 만들기\n",
    "                ################ 내가 원하는 좌표(팔꿈치) - 기준이 되고 싶은 좌표(어깨)\n",
    "                el_l_x, el_l_y, el_l_z = el_l_x-sh_l_x, el_l_y-sh_l_y, el_l_z-sh_l_z\n",
    "                el_r_x, el_r_y, el_r_z = el_r_x-sh_r_x, el_r_y-sh_r_y, el_r_z-sh_r_z\n",
    "                ##### 구면좌표로 변환\n",
    "                l_r, l_theta, l_phi = spherical(el_l_x, el_l_y, el_l_z)\n",
    "                r_r, r_theta, r_phi = spherical(el_r_x, el_r_y, el_r_z)\n",
    "\n",
    "\n",
    "                \n",
    "                ##### 팔의 각도 체크 & 횟수 카운트\n",
    "                if l_theta < 78 :\n",
    "                    feedback_l = \"Raise right!\" ###### 화면 반전으로 왼쪽, 오른쪽 바뀜\n",
    "                    feedback = None\n",
    "                    stateL = \"gg\"\n",
    "                else :\n",
    "                    feedback_l = None\n",
    "                if r_theta < 78 :\n",
    "                    feedback_r = \"Raise left!\"\n",
    "                    feedback = None\n",
    "                    stateR = \"gg\"\n",
    "                else :\n",
    "                    feedback_r = None\n",
    "                if 78<=l_theta and l_theta<=100 and 78<=r_theta and r_theta<=100 and stateL==None and stateR==None :\n",
    "                    feedback = \"GREAT!!\"\n",
    "                    state = \"DOWN\"\n",
    "                    stateL = None\n",
    "                    stateR = None\n",
    "                if 145<l_theta and 145<r_theta and state == \"DOWN\":\n",
    "                    state = \" UP\"\n",
    "                    cnt =1\n",
    "                    if feedback=='GREAT!!':\n",
    "                        g_cnt =1\n",
    "                if l_theta<95 or r_theta<95 :\n",
    "                    feedback = None\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback, feedback_l, feedback_r\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0bfc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # pip install pillow 설치\n",
    "from flask import Flask, Response, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import simplejson as jsonn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c00451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:8080 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise_id :  1652945939422\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-19 17:14:19,386] ERROR in app: Exception on /sendFrame [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_146148\\2362865541.py\", line 33, in chestflyFront\n",
      "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solutions\\pose.py\", line 185, in process\n",
      "    results = super().process(input_data={'image': image})\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solution_base.py\", line 350, in process\n",
      "    self._graph.wait_until_idle()\n",
      "RuntimeError: CalculatorGraph::Run() failed in Run: \n",
      "Calculator::Open() for node \"poselandmarkbyroicpu__inferencecalculator__poselandmarkbyroicpu__InferenceCalculator\" failed: ; RET_CHECK failure (mediapipe/calculators/tensor/inference_calculator_cpu.cc:161) interpreter_\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_146148\\461375552.py\", line 21, in sendFrame1\n",
      "    result_image = chestflyFront(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_146148\\2362865541.py\", line 90, in chestflyFront\n",
      "    cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solution_base.py\", line 566, in __exit__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solution_base.py\", line 368, in close\n",
      "    self._graph.close()\n",
      "RuntimeError: CalculatorGraph::Run() failed in Run: \n",
      "Calculator::Open() for node \"poselandmarkbyroicpu__inferencecalculator__poselandmarkbyroicpu__InferenceCalculator\" failed: ; RET_CHECK failure (mediapipe/calculators/tensor/inference_calculator_cpu.cc:161) interpreter_\n",
      "127.0.0.1 - - [19/May/2022 17:14:19] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 500 -\n",
      "[2022-05-19 17:14:19,402] ERROR in app: Exception on /sendFrame [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_146148\\2362865541.py\", line 33, in chestflyFront\n",
      "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solutions\\pose.py\", line 185, in process\n",
      "    results = super().process(input_data={'image': image})\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solution_base.py\", line 350, in process\n",
      "    self._graph.wait_until_idle()\n",
      "RuntimeError: CalculatorGraph::Run() failed in Run: \n",
      "Calculator::Open() for node \"poselandmarkbyroicpu__inferencecalculator__poselandmarkbyroicpu__InferenceCalculator\" failed: ; RET_CHECK failure (mediapipe/calculators/tensor/inference_calculator_cpu.cc:161) interpreter_\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_146148\\461375552.py\", line 21, in sendFrame1\n",
      "    result_image = chestflyFront(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_146148\\2362865541.py\", line 90, in chestflyFront\n",
      "    cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solution_base.py\", line 566, in __exit__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\mediapipe\\python\\solution_base.py\", line 368, in close\n",
      "    self._graph.close()\n",
      "RuntimeError: CalculatorGraph::Run() failed in Run: \n",
      "Calculator::Open() for node \"poselandmarkbyroicpu__inferencecalculator__poselandmarkbyroicpu__InferenceCalculator\" failed: ; RET_CHECK failure (mediapipe/calculators/tensor/inference_calculator_cpu.cc:161) interpreter_\n",
      "127.0.0.1 - - [19/May/2022 17:14:19] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "count_dict = {}\n",
    "resp_data = {}\n",
    "\n",
    "# 체스트 플라이 정면\n",
    "@app.route('/sendFrame', methods=[\"GET\", \"POST\"])\n",
    "def sendFrame1():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = chestflyFront(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "    cnt = chestflyFront(numpy_image)[1]\n",
    "    g_cnt = chestflyFront(numpy_image)[2]\n",
    "    result_state = chestflyFront(numpy_image)[3]\n",
    "    result_feedback = chestflyFront(numpy_image)[4]\n",
    "    result_feedback_l = chestflyFront(numpy_image)[5]\n",
    "    result_feedback_r = chestflyFront(numpy_image)[6]\n",
    "    result_dis = chestflyFront(numpy_image)[7]\n",
    "    print(result_dis)\n",
    "    \n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback,\n",
    "        'result_feedback_l' : result_feedback_l,\n",
    "        'result_feedback_r' : result_feedback_r,\n",
    "        'result_dis': result_dis\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"localhost\", port=\"8080\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 시티드 로우 측면\n",
    "def sendFrame2():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = seatedrowSide(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "    cnt = seatedrowSide(numpy_image)[1]\n",
    "    g_cnt = seatedrowSide(numpy_image)[2]\n",
    "    result_state = seatedrowSide(numpy_image)[3]\n",
    "    result_feedback = seatedrowSide(numpy_image)[4]\n",
    "    #### 카운트 세기\n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        resp_data['result_cnt'] = 0\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)\n",
    "\n",
    "\n",
    "# 시티드로우 후면\n",
    "@app.route('/sendFrame2', methods=[\"GET\", \"POST\"])\n",
    "def sendFrame3():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = seatedrowBack(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "    cnt = seatedrowBack(numpy_image)[1]\n",
    "    g_cnt = seatedrowBack(numpy_image)[2]\n",
    "    result_state = seatedrowBack(numpy_image)[3]\n",
    "    result_feedback = seatedrowBack(numpy_image)[4]\n",
    "    result_feedback_l = seatedrowBack(numpy_image)[5]\n",
    "    result_feedback_r = seatedrowBack(numpy_image)[6]\n",
    "    #### 카운트 세기\n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        resp_data['result_cnt'] = 0\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback,\n",
    "        'result_feedback_l' : result_feedback_l,\n",
    "        'result_feedback_r' : result_feedback_r\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)\n",
    "\n",
    "\n",
    "# 덤벨 숄더 프레스 #######\n",
    "@app.route('/sendFrame333', methods=[\"GET\", \"POST\"])\n",
    "def sendFrame4():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    print(frame)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = dumbbellFront(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "\n",
    "    cnt = dumbbellFront(numpy_image)[1]\n",
    "    g_cnt = dumbbellFront(numpy_image)[2]\n",
    "    result_state = dumbbellFront(numpy_image)[3]\n",
    "    result_feedback = dumbbellFront(numpy_image)[4]\n",
    "    result_feedback_l = dumbbellFront(numpy_image)[5]\n",
    "    result_feedback_r = dumbbellFront(numpy_image)[6]\n",
    "    #### 카운트 세기\n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        resp_data['result_cnt'] = 0\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback,\n",
    "        'result_feedback_l' : result_feedback_l,\n",
    "        'result_feedback_r' : result_feedback_r\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d72981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c2dc7f55a4afb133f9671f18548a683b80d7f864af89313bd9839ac682f147f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
