{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9486d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24f1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-cors\n",
      "  Using cached Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: Flask>=0.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from flask-cors) (1.1.2)\n",
      "Requirement already satisfied: Six in c:\\users\\user\\anaconda3\\lib\\site-packages (from flask-cors) (1.16.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (8.0.4)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click>=5.1->Flask>=0.9->flask-cors) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=0.9->flask-cors) (2.0.1)\n",
      "Installing collected packages: flask-cors\n",
      "Successfully installed flask-cors-3.0.10\n"
     ]
    }
   ],
   "source": [
    "!pip install -U flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ceab2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.10-cp39-cp39-win_amd64.whl (48.6 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.5.1)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.1)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (1.21.5)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.5.5.64-cp36-abi3-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Installing collected packages: opencv-contrib-python, absl-py, mediapipe\n",
      "Successfully installed absl-py-1.0.0 mediapipe-0.8.10 opencv-contrib-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dc3f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simplejson\n",
      "  Downloading simplejson-3.17.6-cp39-cp39-win_amd64.whl (75 kB)\n",
      "Installing collected packages: simplejson\n",
      "Successfully installed simplejson-3.17.6\n"
     ]
    }
   ],
   "source": [
    "!pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e72fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 거리 구하는 함수\n",
    "def euclidean_distance(pt1, pt2):\n",
    "    distance = 0\n",
    "    for i in range(len(pt1)):\n",
    "        distance += (pt1[i] - pt2[i]) ** 2\n",
    "    return distance ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb93db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "pi = math.pi\n",
    "# 구면 좌표로 변환하는 함수\n",
    "def spherical(x, y, z):\n",
    "    r= np.sqrt(x**2+y**2+z**2)\n",
    "    theta = math.acos(y/r)/pi*180\n",
    "    if x == 0 :\n",
    "        phi = 0\n",
    "    else :\n",
    "        phi = math.atan2(x,z)/pi*180   \n",
    "    return r, theta, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623015ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833b3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f31ad2",
   "metadata": {},
   "source": [
    "--------- 체스트 플라이 정면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc9ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def chestflyFront(data):\n",
    "    annotated_image=None\n",
    "    dis = 0\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "    feedback_l = None\n",
    "    feedback_r = None\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks_3d = results.pose_world_landmarks.landmark  \n",
    "                l_t_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_THUMB.value].x*100\n",
    "                l_t_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_THUMB.value].y*100\n",
    "                l_t_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_THUMB.value].z*100           \n",
    "                left_thumb = [l_t_x, l_t_y, l_t_z]\n",
    "                r_t_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_THUMB.value].x*100\n",
    "                r_t_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_THUMB.value].y*100\n",
    "                r_t_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_THUMB.value].z*100\n",
    "                right_thumb = [r_t_x, r_t_y, r_t_z]\n",
    "                dis = euclidean_distance(left_thumb, right_thumb)\n",
    "\n",
    "\n",
    "                ##### 팔의 위치\n",
    "                if l_t_z>-13 or r_t_z>-13 :\n",
    "                    feedback = None\n",
    "                    if -44.5<=l_t_y and -44.5<=r_t_y :\n",
    "                        feedback = \"GREAT!!\"\n",
    "                        #cv2.rectangle(image, (300, 400), (700, 500), (211, 211, 211), -1)    \n",
    "                        cv2.putText(image, feedback, (int(0.4*w), int(0.98*h)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "                    if l_t_y < -44.5 :\n",
    "                        feedback_l = \"Down left\" ###### 화면 반전으로 왼쪽, 오른쪽 바뀜\n",
    "                        feedback = None\n",
    "                    else :\n",
    "                        feedback_l = None         \n",
    "                    if r_t_y < -44.5 :\n",
    "                        feedback_r = \"Down right\"\n",
    "                        feedback = None\n",
    "                    else :\n",
    "                        feedback_r = None\n",
    "                if dis > 110 :\n",
    "                    state = \"PUSH\"\n",
    "##                if dis < 25 and state == 'PUSH':\n",
    "                if dis < 25:\n",
    "                    state = \"PULL\"\n",
    "                    cnt = 1\n",
    "                    print(\"운동 횟수 : \", cnt)\n",
    "                    if feedback=='GREAT!!':\n",
    "                        g_cnt= 1\n",
    "                        print(\"정자세 횟수 : \", cnt)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback, feedback_l, feedback_r, dis\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaecda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76bdef94",
   "metadata": {},
   "source": [
    "--------- 시티드 로우 측면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cb9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def seatedrowSide(data):\n",
    "    annotated_image=None\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks = results.pose_world_landmarks.landmark\n",
    "                ##### 추출하고자 하는 좌표 추출\n",
    "                ####################  왼쪽 어깨\n",
    "                r_shou = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y,\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z ]\n",
    "                r_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].z]\n",
    "                r_eye = [landmarks[mp_pose.PoseLandmark.RIGHT_EYE.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EYE.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EYE.value].z]\n",
    "                r_ear = [landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].z]\n",
    "                r_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z]\n",
    "                r_shou_x = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x*100\n",
    "                r_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z]\n",
    "                dis = euclidean_distance(r_shou, r_wrist)*100\n",
    "                print(dis)\n",
    "\n",
    "                angle = calculateAngle(r_eye, r_shou, r_hip)\n",
    "                print(angle)\n",
    "                angle_c = calculateAngle(r_shou, r_hip, r_knee)\n",
    "\n",
    "                ##### 팔의 각도 체크 & 횟수 카운트\n",
    "                if dis > 45 :\n",
    "                    state = \"down\"\n",
    "                    stage = \"down\"\n",
    "                    feedback = \"\"\n",
    "                if dis < 34 and state == 'down':\n",
    "                    state = \"up\"\n",
    "                    cnt=1\n",
    "                    print(counter)\n",
    "\n",
    "\n",
    "                if angle < 105 :\n",
    "                    feedback = \"keep your head up\"\n",
    "                if angle > 170 :\n",
    "                    feedback = \"keep your head down\"\n",
    "                if 100 < angle_c < 120 and stage == 'down' :\n",
    "                    stage = 'up'\n",
    "                    feedback = \"great\"\n",
    "                if angle_c > 130 :\n",
    "                    feedback = \"fix your posture\"\n",
    "                    if feedback=='great':\n",
    "                        g_cnt=1\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ecb6d",
   "metadata": {},
   "source": [
    "--------- 시티드 로우 후면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14408a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def seatedrowBack(data):\n",
    "    annotated_image=None\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "    feedback_l = None\n",
    "    feedback_r = None\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks_3d = results.pose_world_landmarks.landmark  \n",
    "                ##### 추출하고자 하는 좌표 추출\n",
    "                ####################  왼쪽 어깨\n",
    "                sh_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x*100\n",
    "                sh_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y*100\n",
    "                sh_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z*100\n",
    "                ####################  왼쪽 팔꿈치\n",
    "                el_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].x*100\n",
    "                el_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].y*100\n",
    "                el_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].z*100\n",
    "                ####################  오른쪽 어깨\n",
    "                sh_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x*100\n",
    "                sh_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y*100\n",
    "                sh_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z*100\n",
    "                ####################  오른쪽 팔꿈치\n",
    "                el_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x*100\n",
    "                el_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y*100\n",
    "                el_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].z*100            \n",
    "                ##### 어깨를 중심으로 만들기\n",
    "                ################ 내가 원하는 좌표(팔꿈치) - 기준이 되고 싶은 좌표(어깨)\n",
    "                el_l_x, el_l_y, el_l_z = el_l_x-sh_l_x, el_l_y-sh_l_y, el_l_z-sh_l_z\n",
    "                el_r_x, el_r_y, el_r_z = el_r_x-sh_r_x, el_r_y-sh_r_y, el_r_z-sh_r_z\n",
    "                ##### 구면좌표로 변환\n",
    "                l_r, l_theta, l_phi = spherical(el_l_x, el_l_y, el_l_z)\n",
    "                r_r, r_theta, r_phi = spherical(el_r_x, el_r_y, el_r_z)\n",
    "\n",
    "\n",
    "                ##### 팔의 각도 체크 & 횟수 카운트\n",
    "                if l_theta > 50 :\n",
    "                    feedback_l = \"Put your left elbows down\"\n",
    "                else :\n",
    "                    feedback_l = \"\"\n",
    "\n",
    "\n",
    "                if r_theta > 50 :\n",
    "                    feedback_r = \"Put your right elbows down\"\n",
    "                else :\n",
    "                    feedback_r = \"\"\n",
    "\n",
    "\n",
    "                if l_phi > 8 :\n",
    "                    state = \"down\"\n",
    "                    feedback=\"\"\n",
    "                if l_phi < -42 and stage == \"down\":\n",
    "                    state = \"up\"\n",
    "                    counter = 1\n",
    "                    feedback=\"\"\n",
    "                    if l_theta <= 49  and r_theta <= 49 :\n",
    "                        feedback=\"great\"\n",
    "                        if feedback==\"great\":\n",
    "                            g_cnt=1\n",
    "                    \n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback, feedback_l, feedback_r\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478abb9",
   "metadata": {},
   "source": [
    "--------- 덤벨 숄더 프레스 정면 ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541e6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "pi = math.pi\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def dumbbellFront(data):\n",
    "    annotated_image=None\n",
    "    cnt = 0\n",
    "    g_cnt = 0\n",
    "    state = None\n",
    "    feedback = None\n",
    "    feedback_l = None\n",
    "    feedback_r = None\n",
    "    BG_COLOR = (192, 192, 192) # gray\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "        for idx, file in enumerate([data]):\n",
    "            ##### 이미지로 테스트할 때는 이렇게\n",
    "            #image = cv2.imread(file)\n",
    "            ##### 실제 연동시에는 이렇게\n",
    "            image = file\n",
    "            image_height, image_width, _ = image.shape\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if not results.pose_world_landmarks:\n",
    "                continue\n",
    "\n",
    "            try :\n",
    "                landmarks_3d = results.pose_world_landmarks.landmark  \n",
    "                ##### 추출하고자 하는 좌표 추출\n",
    "                ####################  왼쪽 어깨\n",
    "                sh_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x*100\n",
    "                sh_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y*100\n",
    "                sh_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z*100\n",
    "                ####################  왼쪽 팔꿈치\n",
    "                el_l_x = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].x*100\n",
    "                el_l_y = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].y*100\n",
    "                el_l_z = landmarks_3d[mp_pose.PoseLandmark.LEFT_ELBOW.value].z*100\n",
    "                ####################  오른쪽 어깨\n",
    "                sh_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x*100\n",
    "                sh_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y*100\n",
    "                sh_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z*100\n",
    "                ####################  오른쪽 팔꿈치\n",
    "                el_r_x = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x*100\n",
    "                el_r_y = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y*100\n",
    "                el_r_z = landmarks_3d[mp_pose.PoseLandmark.RIGHT_ELBOW.value].z*100            \n",
    "                ##### 어깨를 중심으로 만들기\n",
    "                ################ 내가 원하는 좌표(팔꿈치) - 기준이 되고 싶은 좌표(어깨)\n",
    "                el_l_x, el_l_y, el_l_z = el_l_x-sh_l_x, el_l_y-sh_l_y, el_l_z-sh_l_z\n",
    "                el_r_x, el_r_y, el_r_z = el_r_x-sh_r_x, el_r_y-sh_r_y, el_r_z-sh_r_z\n",
    "                ##### 구면좌표로 변환\n",
    "                l_r, l_theta, l_phi = spherical(el_l_x, el_l_y, el_l_z)\n",
    "                r_r, r_theta, r_phi = spherical(el_r_x, el_r_y, el_r_z)\n",
    "\n",
    "\n",
    "                \n",
    "                ##### 팔의 각도 체크 & 횟수 카운트\n",
    "                if l_theta < 78 :\n",
    "                    feedback_l = \"Raise right!\" ###### 화면 반전으로 왼쪽, 오른쪽 바뀜\n",
    "                    feedback = None\n",
    "                    stateL = \"gg\"\n",
    "                else :\n",
    "                    feedback_l = None\n",
    "                if r_theta < 78 :\n",
    "                    feedback_r = \"Raise left!\"\n",
    "                    feedback = None\n",
    "                    stateR = \"gg\"\n",
    "                else :\n",
    "                    feedback_r = None\n",
    "                if 78<=l_theta and l_theta<=100 and 78<=r_theta and r_theta<=100 and stateL==None and stateR==None :\n",
    "                    feedback = \"GREAT!!\"\n",
    "                    state = \"DOWN\"\n",
    "                    stateL = None\n",
    "                    stateR = None\n",
    "                if 145<l_theta and 145<r_theta and state == \"DOWN\":\n",
    "                    state = \" UP\"\n",
    "                    cnt =1\n",
    "                    if feedback=='GREAT!!':\n",
    "                        g_cnt =1\n",
    "                if l_theta<95 or r_theta<95 :\n",
    "                    feedback = None\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
    "            \n",
    "            #return annotated_image\n",
    "    return annotated_image, cnt, g_cnt, state, feedback, feedback_l, feedback_r\n",
    "\n",
    "# # For static images:\n",
    "# IMAGE_FILES = []\n",
    "# file = \"./test.png\"\n",
    "# IMAGE_FILES.append(file)\n",
    "# print(type(IMAGE_FILES))\n",
    "# #imageConvert(IMAGE_FILES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0bfc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # pip install pillow 설치\n",
    "from flask import Flask, Response, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import simplejson as jsonn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c00451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:8080/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise_id :  1652945939422\n",
      "Downloading model to C:\\Users\\user\\anaconda3\\lib\\site-packages\\mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-19 17:35:06,978] ERROR in app: Exception on /sendFrame [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_159280\\2362865541.py\", line 33, in chestflyFront\n",
      "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py\", line 185, in process\n",
      "    results = super().process(input_data={'image': image})\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\", line 340, in process\n",
      "    self._graph.add_packet_to_input_stream(\n",
      "RuntimeError: Graph has errors: \n",
      "Calculator::Open() for node \"poselandmarkbyroicpu__poselandmarkmodelloader__TfLiteModelCalculator\" failed: ; RET_CHECK failure (mediapipe/calculators/tflite/tflite_model_calculator.cc:66) modelFailed to load TfLite model from blob.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_159280\\1843291042.py\", line 21, in sendFrame1\n",
      "    result_image = chestflyFront(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_159280\\2362865541.py\", line 90, in chestflyFront\n",
      "    cv2.imwrite('./result_test' + str(idx) + '.png', annotated_image)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\", line 566, in __exit__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\", line 368, in close\n",
      "    self._graph.close()\n",
      "RuntimeError: CalculatorGraph::Run() failed in Run: \n",
      "Calculator::Open() for node \"poselandmarkbyroicpu__poselandmarkmodelloader__TfLiteModelCalculator\" failed: ; RET_CHECK failure (mediapipe/calculators/tflite/tflite_model_calculator.cc:66) modelFailed to load TfLite model from blob.\n",
      "127.0.0.1 - - [19/May/2022 17:35:06] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise_id :  1652945939422\n",
      "exercise_id :  1652945939422\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-19 17:35:14,410] ERROR in app: Exception on /sendFrame [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_159280\\1843291042.py\", line 63, in sendFrame1\n",
      "    'result_cnt' : cur_count,\n",
      "UnboundLocalError: local variable 'cur_count' referenced before assignment\n",
      "127.0.0.1 - - [19/May/2022 17:35:14] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.07013093144015\n",
      "46.432553566320834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:14] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:17] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise_id :  1652945939422\n",
      "45.433628529123474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:18] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.48699582438585\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:20] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.47428416559012\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:22] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.590594913084225\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:24] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.83582908150613\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:26] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.62568515604305\n",
      "exercise_id :  1652945939422\n",
      "exercise_id :  1652945939422\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:29] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.28036979983926\n",
      "exercise_id :  1652945939422\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:33] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.19749216034571\n",
      "exercise_id :  1652945939422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:36] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.477997376513045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:39] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.52823254291017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:39] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.609351623091875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:40] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.03024049422274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:41] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.129254528527866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/May/2022 17:35:41] \"POST /sendFrame?id=1652945939422 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.34832603358241\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "count_dict = {}\n",
    "resp_data = {}\n",
    "\n",
    "# 체스트 플라이 정면\n",
    "@app.route('/sendFrame', methods=[\"GET\", \"POST\"])\n",
    "def sendFrame1():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = chestflyFront(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "    cnt = chestflyFront(numpy_image)[1]\n",
    "    g_cnt = chestflyFront(numpy_image)[2]\n",
    "    result_state = chestflyFront(numpy_image)[3]\n",
    "    result_feedback = chestflyFront(numpy_image)[4]\n",
    "    result_feedback_l = chestflyFront(numpy_image)[5]\n",
    "    result_feedback_r = chestflyFront(numpy_image)[6]\n",
    "    result_dis = chestflyFront(numpy_image)[7]\n",
    "    print(result_dis)\n",
    "    \n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback,\n",
    "        'result_feedback_l' : result_feedback_l,\n",
    "        'result_feedback_r' : result_feedback_r,\n",
    "        'result_dis': result_dis\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)\n",
    "\n",
    "\n",
    "# 시티드 로우 측면\n",
    "def sendFrame2():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = seatedrowSide(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "    cnt = seatedrowSide(numpy_image)[1]\n",
    "    g_cnt = seatedrowSide(numpy_image)[2]\n",
    "    result_state = seatedrowSide(numpy_image)[3]\n",
    "    result_feedback = seatedrowSide(numpy_image)[4]\n",
    "    #### 카운트 세기\n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        resp_data['result_cnt'] = 0\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)\n",
    "\n",
    "\n",
    "# 시티드로우 후면\n",
    "@app.route('/sendFrame2', methods=[\"GET\", \"POST\"])\n",
    "def sendFrame3():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = seatedrowBack(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "    cnt = seatedrowBack(numpy_image)[1]\n",
    "    g_cnt = seatedrowBack(numpy_image)[2]\n",
    "    result_state = seatedrowBack(numpy_image)[3]\n",
    "    result_feedback = seatedrowBack(numpy_image)[4]\n",
    "    result_feedback_l = seatedrowBack(numpy_image)[5]\n",
    "    result_feedback_r = seatedrowBack(numpy_image)[6]\n",
    "    #### 카운트 세기\n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        resp_data['result_cnt'] = 0\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback,\n",
    "        'result_feedback_l' : result_feedback_l,\n",
    "        'result_feedback_r' : result_feedback_r\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)\n",
    "\n",
    "\n",
    "# 덤벨 숄더 프레스 #######\n",
    "@app.route('/sendFrame333', methods=[\"GET\", \"POST\"])\n",
    "def sendFrame4():\n",
    "#    display(request.args)\n",
    "    exercise_id = request.args['id']\n",
    "    print(\"exercise_id : \", exercise_id)\n",
    "    byteData = request.get_data()\n",
    "    frame = Image.frombuffer('RGBA', (320,240), byteData)\n",
    "    print(frame)\n",
    "    numpy_image=np.array(frame)\n",
    "    resp_data = {}\n",
    "    result_image = dumbbellFront(numpy_image)[0] ###### 넘파이 이미지에 함수를 사용해서 뭔가 결과 내기\n",
    "\n",
    "    cnt = dumbbellFront(numpy_image)[1]\n",
    "    g_cnt = dumbbellFront(numpy_image)[2]\n",
    "    result_state = dumbbellFront(numpy_image)[3]\n",
    "    result_feedback = dumbbellFront(numpy_image)[4]\n",
    "    result_feedback_l = dumbbellFront(numpy_image)[5]\n",
    "    result_feedback_r = dumbbellFront(numpy_image)[6]\n",
    "    #### 카운트 세기\n",
    "    if exercise_id in count_dict:\n",
    "        prev_count = count_dict[exercise_id] \n",
    "        if cnt == 1:\n",
    "            cur_count = prev_count + 1\n",
    "        else :\n",
    "            cur_count = prev_count\n",
    "        count_dict[exercise_id] = cur_count\n",
    "        resp_data['result_cnt'] = cur_count\n",
    "    else:\n",
    "        resp_data['result_cnt'] = 0\n",
    "        count_dict[exercise_id] = 0\n",
    "    #### g_카운트 세기\n",
    "    if exercise_id+\"_g\" in count_dict:\n",
    "        prev_count_g = count_dict[exercise_id+\"_g\"]        \n",
    "        if g_cnt == 1:\n",
    "            cur_count_g = prev_count_g + 1\n",
    "        else :\n",
    "            cur_count_g = prev_count_g\n",
    "        count_dict[exercise_id+\"_g\"] = cur_count_g\n",
    "        resp_data['result_g_cnt'] = cur_count_g\n",
    "    else:\n",
    "        resp_data['result_cnt_g'] = 0\n",
    "        count_dict[exercise_id+\"_g\"] = 0\n",
    "        \n",
    "    if result_image is None :\n",
    "        result_image = numpy_image\n",
    "    ret, buffer = cv2.imencode('.jpg', result_image)\n",
    "    \n",
    "    jpg_as_text = base64.b64encode(buffer)\n",
    "    \n",
    "    resp_data = {\n",
    "        'id': exercise_id,\n",
    "        'result_image' : jpg_as_text,\n",
    "        'result_cnt' : cur_count,\n",
    "        'result_g_cnt' : cur_count_g,\n",
    "        'result_state' : result_state,\n",
    "        'result_feedback' : result_feedback,\n",
    "        'result_feedback_l' : result_feedback_l,\n",
    "        'result_feedback_r' : result_feedback_r\n",
    "    }\n",
    "    ##print(resp_data)\n",
    "    return jsonn.dumps(resp_data)\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"localhost\", port=\"8080\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140c018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d72981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c2dc7f55a4afb133f9671f18548a683b80d7f864af89313bd9839ac682f147f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
